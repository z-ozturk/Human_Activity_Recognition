{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hIx8ho2e9Qx",
        "outputId": "68ada5e1-427e-4cbb-92f1-8905866e58a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Necessary libraries loaded and configuration complete.\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# PROJECT NAME: Activity Recognition on Sensor Data (Project Option 4)\n",
        "# TOPIC: Comparative Analysis of Feature Selection Methods\n",
        "# ZEHRA OZTURK\n",
        "# =============================================================================\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# SECTION 1: LIBRARIES AND CONFIGURATION\n",
        "# -----------------------------------------------------------------------------\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "\n",
        "# Sklearn Modules\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.feature_selection import SelectKBest, f_classif, RFE, SelectFromModel\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, roc_auc_score\n",
        "\n",
        "# Visualization Settings\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams[\"figure.figsize\"] = (12, 7)\n",
        "warnings.filterwarnings('ignore') # Warnings suppressed for a cleaner report\n",
        "\n",
        "print(\"Necessary libraries loaded and configuration complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# SECTION 2: DATA DESCRIPTION & PREPROCESSING\n",
        "# -----------------------------------------------------------------------------\n",
        "# Source: UCI Machine Learning Repository - Human Activity Recognition Using Smartphones\n",
        "\n",
        "# Loading Data\n",
        "# Note: Adjust path for Colab or local directory.\n",
        "train_df = pd.read_csv(r\"/content/train.csv\")\n",
        "test_df = pd.read_csv(r\"/content/test.csv\")\n",
        "\n",
        "print(f\"Training Set Dimensions: {train_df.shape}\")\n",
        "print(f\"Test Set Dimensions:     {test_df.shape}\")\n",
        "\n",
        "# Data Quality Check\n",
        "# Checking for Missing Values and Duplicates\n",
        "if train_df.isnull().sum().sum() == 0:\n",
        "    print(\"Data Quality: No missing values found.\")\n",
        "else:\n",
        "    print(f\"Warning: {train_df.isnull().sum().sum()} missing values detected.\")\n",
        "\n",
        "if train_df.duplicated().sum() == 0:\n",
        "    print(\"Data Quality: No duplicate observations found.\")\n",
        "\n",
        "# Separating Target Variable and Features\n",
        "# The 'subject' column represents the person ID and is excluded from the model.\n",
        "x_train = train_df.drop(['Activity', 'subject'], axis=1)\n",
        "y_train = train_df['Activity']\n",
        "\n",
        "x_test = test_df.drop(['Activity', 'subject'], axis=1)\n",
        "y_test = test_df['Activity']\n",
        "\n",
        "# Target Variable Encoding (Label Encoding)\n",
        "# Categorical activity names (Walking, Sitting, etc.) are converted to numerical format.\n",
        "le = LabelEncoder()\n",
        "y_train_encoded = le.fit_transform(y_train)\n",
        "y_test_encoded = le.transform(y_test)\n",
        "\n",
        "print(f\"\\nClasses: {le.classes_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fr_Mvd8fjC3",
        "outputId": "0a7e027c-f0fd-461c-d815-68529b18c8f3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Set Dimensions: (7352, 563)\n",
            "Test Set Dimensions:     (2947, 563)\n",
            "Data Quality: No missing values found.\n",
            "Data Quality: No duplicate observations found.\n",
            "\n",
            "Classes: ['LAYING' 'SITTING' 'STANDING' 'WALKING' 'WALKING_DOWNSTAIRS'\n",
            " 'WALKING_UPSTAIRS']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# HELPER FUNCTION: MODEL EVALUATION\n",
        "# -----------------------------------------------------------------------------\n",
        "# Calculates Accuracy, F1, AUC, and 5-Fold Cross-Validation (CV).\n",
        "def evaluate_model(model, x_train, y_train, x_test, y_test, method_name, feature_count):\n",
        "    start = time.time()\n",
        "    model.fit(x_train, y_train)\n",
        "    end = time.time()\n",
        "    training_time = end - start\n",
        "\n",
        "    # Predictions\n",
        "    y_pred = model.predict(x_test)\n",
        "    y_pred_proba = model.predict_proba(x_test) # Required for AUC\n",
        "\n",
        "    # Metrics\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    # AUC Calculation (Multi-class 'ovr' - One vs Rest strategy)\n",
        "    try:\n",
        "        auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr', average='weighted')\n",
        "    except:\n",
        "        auc = 0 # In case of potential errors (binary/multi mismatch)\n",
        "\n",
        "    # Cross Validation\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    cv_scores = cross_val_score(model, x_train, y_train, cv=cv, scoring='accuracy')\n",
        "    cv_mean = cv_scores.mean()\n",
        "\n",
        "    print(f\"\\n--- {method_name} RESULTS ---\")\n",
        "    print(f\"Feature Count:       {feature_count}\")\n",
        "    print(f\"Training Time:       {training_time:.4f} sec\")\n",
        "    print(f\"CV Accuracy (Avg):   %{cv_mean*100:.2f}\")\n",
        "    print(f\"Test Accuracy:       %{acc*100:.2f}\")\n",
        "    print(f\"Test F1 Score:       %{f1*100:.2f}\")\n",
        "    print(f\"Test AUC Score:      %{auc*100:.2f}\")\n",
        "\n",
        "    return {\n",
        "        'Method': method_name,\n",
        "        'Feature Count': feature_count,\n",
        "        'Accuracy': acc * 100,\n",
        "        'F1 Score': f1 * 100,\n",
        "        'AUC Score': auc * 100,\n",
        "        'CV Accuracy': cv_mean * 100,\n",
        "        'Training Time (sec)': training_time\n",
        "    }\n",
        "\n",
        "# List to hold results\n",
        "results_list = []"
      ],
      "metadata": {
        "id": "5k8gysF4fsHc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# SECTION 3: BASELINE MODEL (BENCHMARK)\n",
        "# -----------------------------------------------------------------------------\n",
        "# A reference performance is established using all features (561 total).\n",
        "print(\"1. Baseline Model (All Features) Running...\")\n",
        "\n",
        "rf_base = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "res_base = evaluate_model(rf_base, x_train, y_train_encoded, x_test, y_test_encoded,\n",
        "                          \"Baseline (All)\", x_train.shape[1])\n",
        "results_list.append(res_base)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFMAr6OqfzuW",
        "outputId": "4adcb283-9988-42fe-b24f-77613aea3e5d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Baseline Model (All Features) Running...\n",
            "\n",
            "--- Baseline (All) RESULTS ---\n",
            "Feature Count:       561\n",
            "Training Time:       21.5264 sec\n",
            "CV Accuracy (Avg):   %98.16\n",
            "Test Accuracy:       %92.67\n",
            "Test F1 Score:       %92.66\n",
            "Test AUC Score:      %99.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# SECTION 4: FEATURE SELECTION METHODS\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "# Target Feature Count: 100\n",
        "# This number was selected experimentally to retain high variance and distinctive features.\n",
        "k_target = 100\n",
        "\n",
        "# --- METHOD 4.1: FILTER METHOD (ANOVA) ---\n",
        "# Selects based on statistical dependency (ANOVA F-value). Independent of the model.\n",
        "print(\"\\n2. Filter Method (SelectKBest - ANOVA) Running...\")\n",
        "\n",
        "# Important: Fit is ONLY applied to the training set (Preventing Data Leakage)\n",
        "selector_filter = SelectKBest(score_func=f_classif, k=k_target)\n",
        "x_train_filter = selector_filter.fit_transform(x_train, y_train_encoded)\n",
        "x_test_filter = selector_filter.transform(x_test)\n",
        "\n",
        "rf_filter = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "res_filter = evaluate_model(rf_filter, x_train_filter, y_train_encoded, x_test_filter, y_test_encoded,\n",
        "                            \"Filter (ANOVA)\", k_target)\n",
        "results_list.append(res_filter)\n",
        "\n",
        "\n",
        "# --- METHOD 4.2: EMBEDDED METHOD (Tree Importance) ---\n",
        "# Uses the 'feature_importances_' metric inherent to the Random Forest algorithm.\n",
        "print(\"\\n3. Embedded Method (Random Forest Importance) Running...\")\n",
        "\n",
        "# Step 1: Train a temporary model to find importance scores\n",
        "rf_selector = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "rf_selector.fit(x_train, y_train_encoded)\n",
        "\n",
        "# Step 2: Select based on a specific threshold\n",
        "# '1.25*mean' threshold selects features 25% more important than the average.\n",
        "selector_embedded = SelectFromModel(rf_selector, threshold='1.25*mean', prefit=True)\n",
        "x_train_emb = selector_embedded.transform(x_train)\n",
        "x_test_emb = selector_embedded.transform(x_test)\n",
        "\n",
        "num_emb_features = x_train_emb.shape[1]\n",
        "\n",
        "rf_embedded = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "res_embedded = evaluate_model(rf_embedded, x_train_emb, y_train_encoded, x_test_emb, y_test_encoded,\n",
        "                              \"Embedded (RF Imp.)\", num_emb_features)\n",
        "results_list.append(res_embedded)\n",
        "\n",
        "\n",
        "# --- METHOD 4.3: WRAPPER METHOD (RFE) ---\n",
        "# Recursive Feature Elimination: Iteratively eliminates the weakest features.\n",
        "# This is the most computationally expensive method.\n",
        "print(\"\\n4. Wrapper Method (RFE) Running (This may take time)...\")\n",
        "\n",
        "# We use a faster \"estimator\" (DecisionTree) for RFE.\n",
        "# Using RF here would make the processing time excessively long (Computational Efficiency).\n",
        "rfe_estimator = DecisionTreeClassifier(random_state=42)\n",
        "selector_rfe = RFE(estimator=rfe_estimator, n_features_to_select=k_target, step=50)\n",
        "\n",
        "# Measuring Selection Time\n",
        "start_select = time.time()\n",
        "x_train_rfe = selector_rfe.fit_transform(x_train, y_train_encoded)\n",
        "x_test_rfe = selector_rfe.transform(x_test)\n",
        "select_time = time.time() - start_select\n",
        "print(f\"RFE Selection Time: {select_time:.2f} seconds\")\n",
        "\n",
        "rf_wrapper = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "res_wrapper = evaluate_model(rf_wrapper, x_train_rfe, y_train_encoded, x_test_rfe, y_test_encoded,\n",
        "                             \"Wrapper (RFE)\", k_target)\n",
        "\n",
        "# Updating cost by adding selection time to total training time\n",
        "res_wrapper['Training Time (sec)'] += select_time\n",
        "results_list.append(res_wrapper)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hz4eIbCsf3Iq",
        "outputId": "d76ff7e4-e2e7-42da-c505-a37d93f093ec"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "2. Filter Method (SelectKBest - ANOVA) Running...\n",
            "\n",
            "--- Filter (ANOVA) RESULTS ---\n",
            "Feature Count:       100\n",
            "Training Time:       8.5268 sec\n",
            "CV Accuracy (Avg):   %94.68\n",
            "Test Accuracy:       %88.77\n",
            "Test F1 Score:       %88.74\n",
            "Test AUC Score:      %99.09\n",
            "\n",
            "3. Embedded Method (Random Forest Importance) Running...\n",
            "\n",
            "--- Embedded (RF Imp.) RESULTS ---\n",
            "Feature Count:       97\n",
            "Training Time:       7.8532 sec\n",
            "CV Accuracy (Avg):   %98.01\n",
            "Test Accuracy:       %90.50\n",
            "Test F1 Score:       %90.48\n",
            "Test AUC Score:      %99.18\n",
            "\n",
            "4. Wrapper Method (RFE) Running (This may take time)...\n",
            "RFE Selection Time: 50.75 seconds\n",
            "\n",
            "--- Wrapper (RFE) RESULTS ---\n",
            "Feature Count:       100\n",
            "Training Time:       9.0951 sec\n",
            "CV Accuracy (Avg):   %98.37\n",
            "Test Accuracy:       %91.92\n",
            "Test F1 Score:       %91.92\n",
            "Test AUC Score:      %99.46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# SECTION 5: COMPARATIVE PERFORMANCE EVALUATION\n",
        "# -----------------------------------------------------------------------------\n",
        "df_results = pd.DataFrame(results_list)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"FINAL COMPARISON TABLE\")\n",
        "print(\"=\"*50)\n",
        "display(df_results)\n",
        "\n",
        "# Visualization 1: Accuracy and F1 Score\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "df_melted = df_results.melt(id_vars=\"Method\", value_vars=[\"Accuracy\", \"F1 Score\", \"CV Accuracy\"], var_name=\"Metric\", value_name=\"Score\")\n",
        "sns.barplot(x=\"Method\", y=\"Score\", hue=\"Metric\", data=df_melted, palette=\"viridis\")\n",
        "plt.ylim(85, 100)\n",
        "plt.title(\"Performance Metrics by Method\")\n",
        "plt.xticks(rotation=15)\n",
        "\n",
        "# Visualization 2: Computational Cost (Time)\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.barplot(x=\"Method\", y=\"Training Time (sec)\", data=df_results, palette=\"Reds\")\n",
        "plt.title(\"Computational Cost (Time)\")\n",
        "plt.ylabel(\"Seconds (Lower is Better)\")\n",
        "plt.xticks(rotation=15)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "557HYQH3f_z8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# SECTION 6: INTERPRETABILITY AND DOMAIN KNOWLEDGE\n",
        "# -----------------------------------------------------------------------------\n",
        "# Evaluation of significance within the problem context.\n",
        "\n",
        "print(\"\\n--- INTERPRETABILITY ANALYSIS (Embedded Method) ---\")\n",
        "# Getting names of features selected by the embedded method\n",
        "mask = selector_embedded.get_support()\n",
        "selected_feat_names = x_train.columns[mask]\n",
        "\n",
        "# Distribution by sensor type\n",
        "acc_features = [f for f in selected_feat_names if 'Acc' in f]\n",
        "gyro_features = [f for f in selected_feat_names if 'Gyro' in f]\n",
        "\n",
        "print(f\"Model selected a total of {len(selected_feat_names)} features.\")\n",
        "print(f\"{len(acc_features)} of these are 'Accelerometer' (Acc) data.\")\n",
        "print(f\"{len(gyro_features)} of these are 'Gyroscope' (Gyro) data.\")\n",
        "\n",
        "print(\"\\nComment:\")\n",
        "if len(acc_features) > len(gyro_features):\n",
        "    print(\"Results indicate that linear acceleration (Acc) is more deterministic than\\n\"\n",
        "          \"angular change (Gyro) in distinguishing human activity (Walking, Sitting, etc.).\\n\"\n",
        "          \"This is consistent with findings in the literature (Anguita et al., 2013).\")\n",
        "else:\n",
        "    print(\"Results indicate that gyroscope data plays a critical role in classification.\")\n",
        "\n",
        "print(\"\\n--- PROJECT COMPLETED ---\")"
      ],
      "metadata": {
        "id": "zlXHvV_tgCOA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}